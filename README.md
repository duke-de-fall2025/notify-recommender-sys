# ğŸ”” Notify: Real-Time Personalised Notification System

[![Python Template for IDS706](https://github.com/duke-de-fall2025/notify-recommender-sys/actions/workflows/main.yml/badge.svg)](https://github.com/duke-de-fall2025/notify-recommender-sys/actions/workflows/main.yml)

**Notify** is a production-grade, ML-powered real-time notification platform delivering hyper-personalised campaigns at scale.

**Team:** Pranshul, Sejal, Kedar, Shambhavi, Supriya

---

## ğŸ¥ Demo Video

**ğŸ“¹ Watch the System in Action:**

ğŸ‘‰ **[View Demo on Google Drive](https://drive.google.com/file/d/1UuUn7b9tgiD0I8TgcvihzxDXPbwOCWvR/view?usp=sharing)**

**ğŸ“Š Presentation Slides:**

ğŸ‘‰ **[View Slides (Demo Slides PDF)](./DemoSlides.pdf)**

---

### Problem & Solution

| Challenge | Solution |
|-----------|----------|
| Generic notifications | ML-driven personalization |
| Poor timing | Intelligent scheduling |
| Rule-based targeting | Real-time embeddings + ANN search |
| No feedback loop | Closed-loop learning system |

## Architecture at a Glance

```
Frontend (Web/App) â†’ Kafka Streaming â†’ DynamoDB
                              â†“
                     Airflow ML Pipeline
                     (Products â†’ Purchases â†’ Users)
                              â†“
                  Lambda Recommendations (ANN)
                              â†“
                EventBridge Scheduling & Delivery
                              â†“
                  User Interactions (Feedback Loop)
```

---

## ğŸ“Š System Components

### 1ï¸âƒ£ Event Ingestion & Streaming

| Component | Role |
|-----------|------|
| Frontend | Web/Mobile user interactions |
| Kafka | Real-time event streaming |
| Topics | `purchase_history`, `notify_clickstream` |

### 2ï¸âƒ£ Data Storage & Features

| Table | Purpose |
|-------|---------|
| `notify_users` | Core user profiles |
| `notify_user_features` | Behavioural features (avg order value, spend, categories, etc.) |
| `notify_products` | Product catalogue |
| `notify_product_features` | Sales metrics (revenue, avg price, etc.) |
| `notify_campaigns` | Campaign metadata & scheduling |
| `notify_user_product_matrix` | Interaction strength matrix |
| `notify_purchase_history` | Historical transactions |

**Storage:** DynamoDB (low-latency, serverless, auto-scaling)

### 3ï¸âƒ£ ML Pipeline (MWAA/Airflow)

**Dependency Chain:**
```
Products â†’ Product Embeddings
    â†“
Purchase Orders â†’ Purchase Embeddings
    â†“
User Data â†’ User Embeddings
(Independent) â†’ Campaign Embeddings
```

**Features:** Hierarchical DAGs, delta updates, embeddings persisted in DynamoDB

### 4ï¸âƒ£ Recommendation Engine (Lambda)

- **Input:** User + Campaign embeddings
- **Algorithm:** Cosine similarity + ANN search O(log n)
- **Output:** Top-10 personalised campaigns per user
- **Performance:** Real-time inference at scale

### 5ï¸âƒ£ Scheduling & Delivery

- **Constraints:** Max 5 notifications/user/day, time windows, priority, fatigue control
- **Plan:** 24-hour optimised schedule per user
- **Delivery:** EventBridge triggers Lambda every minute
- **Feedback:** User interactions feed back into clickstream (closed-loop)

---

## ğŸ› ï¸ Technology Stack

| Layer | Technology |
|-------|-----------|
| Frontend | Python |
| Streaming | Kafka |
| Batch Ingestion | AWS Glue |
| Database | DynamoDB |
| Orchestration | Amazon MWAA (Airflow) |
| ML | BERT Embeddings, ANN Search |
| Compute | AWS Lambda, EC2 |
| Scheduling | Amazon EventBridge |

---

## ğŸ”„ End-to-End Flow

1. Users interact â†’ Kafka streams events
2. Glue ingests historical data â†’ DynamoDB
3. Airflow generates embeddings (Products â†’ Purchases â†’ Users)
4. Lambda computes Top-10 recommendations via ANN
5. Scheduler enforces constraints (fatigue, priority, time windows)
6. EventBridge triggers delivery every minute
7. User responses captured â†’ Feedback loop improves future recommendations

---

## ğŸ“ Project Structure

```
notify-recommender-sys/
â”œâ”€â”€ app.py                          # Main application
â”œâ”€â”€ consumer.py                     # Kafka consumer
â”œâ”€â”€ test_app.py                     # Tests
â”œâ”€â”€ requirements.txt                # Dependencies
â”œâ”€â”€ docker-compose.yml              # Docker setup
â”œâ”€â”€ dockerfile.consumer
â”œâ”€â”€ dockerfile.streamlit
â”‚
â”œâ”€â”€ batch-ingestion/                # AWS Glue jobs
â”‚   â”œâ”€â”€ glue_notify_*.py            # Data ingestion pipelines
â”‚   â””â”€â”€ campaigns.csv               # Sample data
â”‚
â”œâ”€â”€ embedding-orchestrator/         # Airflow DAGs
â”‚   â”œâ”€â”€ dag.py                      # Main embedding DAG
â”‚   â””â”€â”€ delta_update_dag.py         # Incremental updates
â”‚
â”œâ”€â”€ notif-recommendation-engine/    # Recommendation logic
â”‚   â”œâ”€â”€ recommender.py
â”‚   â”œâ”€â”€ cosine_similarity.py
â”‚   â”œâ”€â”€ notification_user_mapping.py
â”‚   â”œâ”€â”€ schedule_notifications.py
â”‚   â”œâ”€â”€ products_eda.ipynb
â”‚   â”œâ”€â”€ users_eda.ipynb
â”‚   â””â”€â”€ *.csv                       # Sample data
â”‚
â””â”€â”€ output/                         # Generated artifacts
    â”œâ”€â”€ recommendations.csv
    â””â”€â”€ dynamodb_records.json
```

---

## ğŸš€ Getting Started

1. **AWS Setup:** Configure DynamoDB, Glue jobs, MWAA
2. **Kafka:** Set up Kafka brokers
3. **Deploy DAGs:** Upload to MWAA
4. **Deploy Lambdas:** Recommendation & scheduling functions
5. **Run Ingestion:** Execute Glue jobs
6. **Start Streaming:** Begin event processing
7. **Monitor:** CloudWatch + MWAA UI

---

## ğŸ“‹ Requirements & Specifications

### ğŸ“Œ Functional & Non-Functional Requirements

For comprehensive details on system requirements, performance metrics, scalability targets, SLAs, and design principles, see:

ğŸ‘‰ **[Functional & Non-Functional Requirements](./Functional_and_nonFunctionRequirements.md)**

This document includes:
- **Functional Requirements:** 8 core system capabilities
- **Performance SLAs:** Latency, throughput, and availability targets
- **Scalability:** User capacity, event throughput, notification volume
- **Reliability:** Fault tolerance, data consistency, disaster recovery
- **Cost & Monitoring:** Budget targets, observability metrics
- **Design Principles:** Serverless-first, event-driven, cost-optimized

### ğŸ”Œ API Contracts & Integration Guide

For detailed API specifications, request/response schemas, error handling, and integration examples, see:

ğŸ‘‰ **[API Contracts Documentation](./API_CONTRACTS.md)**

This document provides:
- **Recommendation Engine APIs:** Get top-10 personalised campaigns, user embedding lookup
- **Scheduling APIs:** Create optimised 24-hour schedules, EventBridge integration
- **Request/Response Schemas:** Complete JSON specifications with field descriptions
- **Error Handling:** Standardised error responses with HTTP status codes and retry policies
- **SLAs & Performance:** â‰¤200ms P95 latency, 99.95% availability, 99.9% success rate
- **Integration Examples:** End-to-end workflow examples and error handling patterns
- **Data Models:** Campaign, user embedding, and notification schedule object schemas

All APIs are implemented as **AWS Lambda functions** and are fully serverless, event-driven, and designed for high-throughput real-time processing.

---

## ğŸ“ˆ Business Impact

- âœ… Hyper-personalised engagement
- âœ… Higher conversion rates
- âœ… Reduced user fatigue
- âœ… Data-driven prioritisation

---

## ğŸ›ï¸ Technical Excellence

- Cloud-native & serverless
- Real-time event processing
- Scalable ML inference
- Fault-tolerant orchestration
- Closed-loop learning

---

## ğŸ“ Contact & Support

For questions or contributions, reach out to the team or open an issue.